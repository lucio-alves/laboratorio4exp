"""
====================================================
VALIDA√á√ÉO DO PILAR 1 (ENGAJAMENTO) - VERS√ÉO FINAL v2
====================================================

Objetivo:
Validar as m√©tricas de engajamento para os reposit√≥rios
da Fase 1 de forma r√°pida e eficiente, com tratamento de
erros para commits n√£o vinculados.

Depend√™ncias:
    pip install PyGithub pandas openpyxl
    (opcional) pip install python-dotenv

Entradas:
    - dataset_fase1_validacao-v2.xlsx
      (deve conter as colunas: URL, Data de morte, Data de ressurrei√ß√£o)

Sa√≠da:
    - validacao_pilar1_completo_final_v2.xlsx

Autor: [Seu Nome] & Gemini
====================================================
"""

from dotenv import load_dotenv
import os
import pandas as pd
import re
from datetime import timedelta, datetime
from github import Github, Auth, GithubException

# ====================================================
# üîê Carregar token do .env
# ====================================================
load_dotenv()

token = os.getenv("GITHUB_TOKEN")
if not token:
    raise EnvironmentError("‚ö†Ô∏è Defina o GITHUB_TOKEN no arquivo .env")

auth = Auth.Token(token)
g = Github(auth=auth, per_page=100)

# ====================================================
# üìò Leitura do dataset base
# ====================================================
df_base = pd.read_excel("dataset_fase1_validacao-v2.xlsx")

repo_col = "URL"
data_dead_col = "Data de morte"
data_revive_col = "Data de ressurrei√ß√£o"

# ====================================================
# üîß Fun√ß√£o para extrair owner/repo da URL
# ====================================================
def extrair_owner_repo(url):
    match = re.search(r"github\.com/([\w\-_.]+/[\w\-_.]+)", url)
    if match:
        return match.group(1)
    else:
        raise ValueError(f"URL inv√°lida: {url}")

# ====================================================
# üìà Fun√ß√µes de An√°lise (Refatoradas para receber dados)
# ====================================================

# --- Fun√ß√µes que n√£o dependem do hist√≥rico (r√°pidas) ---
def tem_documentacao(repo):
    try:
        contents = repo.get_contents("")
        files = [f.path.lower() for f in contents]
        return any(x in str(files) for x in ["contributing.md", "code_of_conduct.md", "readme.md"])
    except Exception:
        return False

def adocao_ci(repo, data_revive):
    try:
        paths = [".github/workflows", ".travis.yml"]
        for path in paths:
            commits = repo.get_commits(path=path, since=data_revive)
            if commits.totalCount > 0:
                return True
        return False
    except GithubException as e:
        if e.status == 404: return False
        print(f"  (Info) Erro ao checar CI: {e}")
        return False
    except Exception:
        return False

def identifica_novos_mantenedores(repo, data_revive):
    return "N√£o aplic√°vel (Limita√ß√£o da API)"

# --- Fun√ß√µes que agora processam listas pr√©-buscadas ---

def conta_mencoes_incentivo(issues_list):
    count = 0
    for issue in issues_list:
        text = (issue.title or "") + " " + (issue.body or "")
        if re.search(r"good first issue|hacktoberfest", text, re.IGNORECASE):
            count += 1
    return count

def comentarios_antes_depois(issues_list, data_revive):
    antes, depois = [], []
    for i in issues_list:
        if i.created_at < data_revive:
            antes.append(i)
        else:
            depois.append(i)

    media_antes = sum(i.comments for i in antes) / len(antes) if antes else 0
    media_depois = sum(i.comments for i in depois) if depois else 0
    return media_antes, media_depois

# <<< FUN√á√ÉO CORRIGIDA >>>
def diversidade_contribuidores(commits_list, data_revive):
    """
    Conta n√∫mero de contribuidores √∫nicos antes e depois (M1.2.2).
    VERS√ÉO CORRIGIDA: Lida com commits cujo autor n√£o √© um usu√°rio do GitHub.
    """
    antes, depois = set(), set()
    for c in commits_list:
        # A verifica√ß√£o 'if c.author:' √© a forma mais segura. Se o autor do commit
        # n√£o for um usu√°rio do GitHub, c.author ser√° 'None' e o c√≥digo interno n√£o ser√° executado.
        if c.author:
            commit_date = c.commit.author.date
            if commit_date < data_revive:
                antes.add(c.author.login)
            else:
                depois.add(c.author.login)
    return len(antes), len(depois)

def taxa_fechamento_issues(issues_list):
    fechadas, fechadas_rapidas = 0, 0
    for issue in issues_list:
        if issue.state == 'closed':
            fechadas += 1
            if issue.closed_at and issue.created_at:
                if (issue.closed_at - issue.created_at).days <= 30:
                    fechadas_rapidas += 1
    return round(fechadas_rapidas / fechadas, 3) if fechadas > 0 else 0

def frequencia_interacao_mantenedores(repo, issues_list, data_revive):
    tempos_antes, tempos_depois = [], []
    mantenedores = {repo.owner.login}

    for issue in issues_list:
        if issue.user.login in mantenedores:
            continue
        try:
            for comment in issue.get_comments():
                if comment.user.login in mantenedores:
                    delta = (comment.created_at - issue.created_at).total_seconds() / 3600
                    if issue.created_at < data_revive:
                        tempos_antes.append(delta)
                    else:
                        tempos_depois.append(delta)
                    break
        except Exception as e:
            print(f"  (Info) N√£o foi poss√≠vel buscar coment√°rios da issue #{issue.number}: {e}")

    media_antes = sum(tempos_antes) / len(tempos_antes) if tempos_antes else 0
    media_depois = sum(tempos_depois) / len(tempos_depois) if tempos_depois else 0
    return round(media_antes, 2), round(media_depois, 2)

def conta_mencoes_eventos_externos(issues_list):
    count = 0
    keywords = r"sponsor|sponsorship|funding|conference|patroc√≠nio|financiamento|confer√™ncia"
    for issue in issues_list:
        text = (issue.title or "") + " " + (issue.body or "")
        if re.search(keywords, text, re.IGNORECASE):
            count += 1
    return count

# ====================================================
# üöÄ Loop Principal Otimizado
# ====================================================
resultados = []

for idx, row in df_base.iterrows():
    url_repo = row[repo_col]
    try:
        repo_name = extrair_owner_repo(url_repo)
    except ValueError as e:
        print(f"‚ö†Ô∏è {e}")
        continue

    data_dead = pd.to_datetime(row[data_dead_col]).tz_localize('UTC')
    data_revive = pd.to_datetime(row[data_revive_col]).tz_localize('UTC')
    analysis_start_date = data_dead - timedelta(days=365)

    print(f"üîç Analisando {repo_name} ({idx+1}/{len(df_base)})")

    try:
        repo = g.get_repo(repo_name)

        print(f"  Buscando dados desde {analysis_start_date.date()}...")
        all_issues_in_window = list(repo.get_issues(state="all", since=analysis_start_date))
        all_commits_in_window = list(repo.get_commits(since=analysis_start_date))
        print(f"  Encontrados {len(all_issues_in_window)} issues e {len(all_commits_in_window)} commits.")

        print("  Processando m√©tricas...")
        docs = tem_documentacao(repo)
        ci_adotado = adocao_ci(repo, data_revive)
        novos_maintainers = identifica_novos_mantenedores(repo, data_revive)
        incentivos = conta_mencoes_incentivo(all_issues_in_window)
        com_antes, com_depois = comentarios_antes_depois(all_issues_in_window, data_revive)
        div_antes, div_depois = diversidade_contribuidores(all_commits_in_window, data_revive) # Chamada da fun√ß√£o corrigida
        taxa_fechamento = taxa_fechamento_issues(all_issues_in_window)
        mencoes_eventos = conta_mencoes_eventos_externos(all_issues_in_window)
        tempo_resp_antes, tempo_resp_depois = frequencia_interacao_mantenedores(repo, all_issues_in_window, data_revive)

        resultados.append({
            "repo": repo_name,
            "tem_documentacao": docs,
            "men√ß√µes_incentivo": incentivos,
            "tempo_resposta_mantenedor_antes_h": tempo_resp_antes,
            "tempo_resposta_mantenedor_depois_h": tempo_resp_depois,
            "coment√°rios_m√©dios_antes": round(com_antes, 2),
            "coment√°rios_m√©dios_depois": round(com_depois, 2),
            "diversidade_contrib_antes": div_antes,
            "diversidade_contrib_depois": div_depois,
            "taxa_fechamento_30d": taxa_fechamento,
            "ci_adotado_pos_revive": ci_adotado,
            "novos_mantenedores_pos_revive": novos_maintainers,
            "men√ß√µes_eventos_externos": mencoes_eventos,
        })

    except Exception as e:
        print(f"‚ùå Erro CR√çTICO ao processar {repo_name}: {e}")
        continue

# ====================================================
# üíæ Exporta√ß√£o dos Resultados Consolidados
# ====================================================
df_result = pd.DataFrame(resultados)
output_filename = "validacao_pilar1_completo_final_v2.xlsx"
df_result.to_excel(output_filename, index=False)
print(f"\n‚úÖ Arquivo '{output_filename}' gerado com sucesso!")